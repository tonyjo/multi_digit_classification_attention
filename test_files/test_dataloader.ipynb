{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from src.model import Model as Attn_Model\n",
    "from src.baseline_classify import Model as Clfy_Model\n",
    "from src.data_loader_seq_classify import dataLoader\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (3.0, 3.0)  # set default size of plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data-loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset\n",
    "data = dataLoader(directory='./dataset', width=16, height=16,\\\n",
    "                  dataset_dir='test_cropped',\\\n",
    "                  dataset_name='test.txt', max_steps=7, mode='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = data.all_data\n",
    "# data2 = data.all_seq_data\n",
    "\n",
    "# print(len(data1))\n",
    "# print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.gen_data_batch(batch_size=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_seq=[]\n",
    "lbl_img=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(27):\n",
    "    _, _, image_batch, label_batch = next(test_loader)\n",
    "    lbl_seq.append(label_batch)\n",
    "    lbl_img.append(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lbl_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = lbl_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll1 = ll[0]\n",
    "len(ll1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = lbl_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0496079410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot original image\n",
    "fig,ax = plt.subplots(1, len(l2))\n",
    "for T in range(len(l2)):\n",
    "    ax[T].imshow((l2[T] + 1)*127.5)\n",
    "    ax[T].text(0, 1, (ll1[T]), color='black', backgroundcolor='white', fontsize=8)\n",
    "    ax[T].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "img_size    = (16,16)\n",
    "max_steps   = 7\n",
    "width       = img_size[0]\n",
    "height      = img_size[1]\n",
    "batch_size  = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_pred_bboxs(pred_bboxes):\n",
    "    \"\"\"\n",
    "    The first step and last step are start and stop state\n",
    "    \"\"\"\n",
    "    def box_threshold(left, top, width, height):\n",
    "        valid_box = False\n",
    "        # If the threshold box is less than 10\n",
    "        if width * height < 10:\n",
    "            valid_box = False\n",
    "        elif int(left) == 0 and int(top) == 0 and\\\n",
    "             int(width) == 0 and int(height) == 0:\n",
    "            valid_box = False\n",
    "        else:\n",
    "            valid_box = True\n",
    "\n",
    "        return valid_box\n",
    "\n",
    "    valid_pred_bboxs = []\n",
    "    for t in range(batch_size):\n",
    "        interm_pred_bboxs = []\n",
    "        for T in range(max_steps):\n",
    "            # Ignore first and last prediction\n",
    "            if T != 0 and T+1 != max_steps:\n",
    "                # Predicted bounding box\n",
    "                smple_left   = pred_bboxes[t][T][0][0]\n",
    "                smple_top    = pred_bboxes[t][T][0][1]\n",
    "                smple_width  = pred_bboxes[t][T][0][2]\n",
    "                smple_height = pred_bboxes[t][T][0][3]\n",
    "                # Check if the box is valid\n",
    "                vld_bbx_pred = box_threshold(left=smpl_left, top=smple_top,\\\n",
    "                                     width=smple_width, height=smple_height)\n",
    "                # Collect if valid box\n",
    "                if vld_bbx_pred:\n",
    "                    interm_pred_bboxs.append([smple_left, smple_top, smple_width, smple_height])\n",
    "        # Collect\n",
    "        valid_pred_bboxs.append(interm_pred_bboxs)\n",
    "\n",
    "    return valid_pred_bboxs\n",
    "\n",
    "def crop_and_resize(images, bboxes):\n",
    "    images_crop_resize = []\n",
    "    for t in range(len(bboxes)):\n",
    "        image = images[t] # Sample image\n",
    "        bbox  = bboxes[t] # Sample predictions\n",
    "        interm_images_crop_resize = []\n",
    "        # Loop through predictions\n",
    "        for bbx in bbox:\n",
    "            sample_left   = abs(int(bbx[0]))\n",
    "            sample_top    = abs(int(bbx[1]))\n",
    "            sample_width  = abs(int(bbx[2]))\n",
    "            sample_height = abs(int(bbx[3]))\n",
    "\n",
    "            image_patch = image[sample_top:sample_top+sample_height, sample_left:sample_left+sample_width, :]\n",
    "            # Zooming\n",
    "            image_patch_rz = cv2.resize(image_patch, (width, height), interpolation = cv2.INTER_AREA)\n",
    "            # Normalize image between -1 and 1\n",
    "            image_patch_rz = image_patch_rz /127.5 - 1.0\n",
    "            # Collect\n",
    "            interm_images_crop_resize.append(image_patch_rz)\n",
    "        # Append to main\n",
    "        images_crop_resize.append(interm_images_crop_resize)\n",
    "\n",
    "    return images_crop_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Attention Model\n",
    "attn_model = Attn_Model(dim_feature=[49, 128], dim_hidden=128, n_time_step=7,\n",
    "              alpha_c=1.0, image_height=64, image_width=64, mode='test')\n",
    "# Load\n",
    "clfy_model = Clfy_Model(image_height=16, image_width=16, l2=0.0002, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  13068\n",
      "Batch size: 44\n",
      "Iterations: 297\n"
     ]
    }
   ],
   "source": [
    "test_loader = data.gen_data_batch(batch_size)\n",
    "n_examples  = data.max_length\n",
    "n_iters     = int(np.ceil(float(n_examples)/batch_size))\n",
    "# Total Char\n",
    "total_char = 0.0\n",
    "# Summary\n",
    "print(\"Data size:  %d\" %n_examples)\n",
    "print(\"Batch size: %d\" %batch_size)\n",
    "print(\"Iterations: %d\" %n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN build model sucess!\n",
      "Classification build model sucess!\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "pred_bboxs_, _    = attn_model.build_test_model()\n",
    "_, predictions    = clfy_model.build_test_model()\n",
    "# Classification score\n",
    "check_predictions = tf.equal(predictions, tf.argmax(clfy_model.labels, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(check_predictions, tf.float32))\n",
    "\n",
    "# Set GPU options\n",
    "config = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e1e23f5baa4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del predicted_bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "image_batch, image_norm_batch, label_batch = next(test_loader)\n",
    "print(image_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing with Classification Model with random weights...\n",
      "Start testing with Attention Model with random weights...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-63f927278247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Run bounding box prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpredicted_bboxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_bboxs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mvald_prdct_bbxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_pred_bboxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_bboxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_bboxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mimages_crop_rez\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_and_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvald_prdct_bbxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimages_crop_rez\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_crop_rez\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-83de339aa072>\u001b[0m in \u001b[0;36mvalid_pred_bboxs\u001b[0;34m(pred_bboxes)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# Predicted bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0msmple_left\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpred_bboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0msmple_top\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mpred_bboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0msmple_width\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpred_bboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=config)) as sess:\n",
    "    # Intialize the training graph\n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "    # Tensorboard summary path\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    print(\"Start testing with Classification Model with random weights...\")\n",
    "    print(\"Start testing with Attention Model with random weights...\")\n",
    "\n",
    "    total_acc = 0.0\n",
    "\n",
    "    image_batch, image_norm_batch, label_batch = next(test_loader)\n",
    "    ## Box Prediction\n",
    "    feed_dict = {attn_model.images: image_norm_batch,\n",
    "                 attn_model.drop_prob: 1.0}\n",
    "    # Run bounding box prediction\n",
    "    predicted_bboxs = sess.run(pred_bboxs_, feed_dict)\n",
    "    vald_prdct_bbxs = valid_pred_bboxs(pred_bboxes=predicted_bboxs)\n",
    "    images_crop_rez = crop_and_resize(images=image_batch, bboxes=vald_prdct_bbxs)\n",
    "    images_crop_rez = np.array(images_crop_rez)\n",
    "    print()\n",
    "    ## Digit classification\n",
    "    for k in range(len(images_crop_rez)):\n",
    "        each_predt_images = np.array(images_crop_rez[k])\n",
    "        each_image_labels = label_batch[k]\n",
    "        # Check if prediction batch equals label_batch,\n",
    "        # if not select upto of the label batch\n",
    "        if len(each_predt_images) > len(each_image_labels):\n",
    "            each_predt_images = each_predt_images[0:len(each_image_labels), :, :, :]\n",
    "        elif len(each_predt_images) < len(each_image_labels):\n",
    "            each_predt_images_trim = each_predt_images[0:len(each_predt_images), :, :, :]\n",
    "        # Increment total characters using the orginal sequence not the trim\n",
    "        total_char += len(each_image_labels)\n",
    "        ## Digit Prediction\n",
    "        feed_dict = {clfy_model.images: each_predt_images_trim,\n",
    "                     clfy_model.labels: each_image_labels,\n",
    "                     clfy_model.drop_prob: 1.0}\n",
    "        # Run bounding\n",
    "        accu, pred = sess.run([accuracy, predictions], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_threshold(left, top, width, height):\n",
    "    valid_box = False\n",
    "    print(width * height)\n",
    "    # If the threshold box is less than 10\n",
    "    if width * height < 10:\n",
    "        valid_box = False\n",
    "    elif int(left) == 0 and int(top) == 0 and\\\n",
    "         int(width) == 0 and int(height) == 0:\n",
    "        valid_box = False\n",
    "    else:\n",
    "        valid_box = True\n",
    "\n",
    "    return valid_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_pred_bboxs(pred_bboxes):\n",
    "    valid_pred_bboxs = []\n",
    "    for t in range(batch_size):\n",
    "        interm_pred_bboxs = []\n",
    "        for T in range(max_steps):\n",
    "            # Ignore first and last prediction\n",
    "            if T != 0 and T+1 != max_steps:\n",
    "                # Predicted bounding box\n",
    "                smple_left   = abs(pred_bboxes[T][t][0])\n",
    "                smple_top    = abs(pred_bboxes[T][t][1])\n",
    "                smple_width  = abs(pred_bboxes[T][t][2])\n",
    "                smple_height = abs(pred_bboxes[T][t][3])\n",
    "                # Check if the box is valid\n",
    "                vld_bbx_pred = box_threshold(left=smple_left, top=smple_top,\\\n",
    "                                     width=smple_width, height=smple_height)\n",
    "                # Collect if valid box\n",
    "                if vld_bbx_pred:\n",
    "                    interm_pred_bboxs.append([smple_left, smple_top, smple_width, smple_height])\n",
    "        # Collect\n",
    "        valid_pred_bboxs.append(interm_pred_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014883008\n",
      "0.011749274\n",
      "0.0061300127\n",
      "0.0012396609\n",
      "0.009899711\n",
      "0.0005871639\n",
      "0.0030439636\n",
      "0.009103718\n",
      "0.015955519\n",
      "0.022211248\n",
      "0.0006621551\n",
      "0.00047915822\n",
      "0.0060281255\n",
      "0.013906489\n",
      "0.021707619\n",
      "1.50129745e-05\n",
      "7.1338914e-06\n",
      "0.0005797923\n",
      "0.0025435947\n",
      "0.0059760935\n",
      "0.00079473504\n",
      "0.0010871042\n",
      "0.0021354575\n",
      "0.00086879206\n",
      "0.008607927\n",
      "0.0009475483\n",
      "0.00014701828\n",
      "8.925074e-05\n",
      "0.0038721135\n",
      "0.011279314\n",
      "0.0006327236\n",
      "0.00057044416\n",
      "0.0011321605\n",
      "0.0013351438\n",
      "0.0014274555\n",
      "0.00054664497\n",
      "0.00027542718\n",
      "0.005289813\n",
      "0.01759072\n",
      "0.034720622\n",
      "0.0010515897\n",
      "0.0012190399\n",
      "0.0059653562\n",
      "0.01121058\n",
      "0.015657023\n",
      "0.0021165193\n",
      "0.001138083\n",
      "0.00803649\n",
      "0.016679928\n",
      "0.025031846\n",
      "8.109698e-05\n",
      "0.0006093914\n",
      "0.0018771905\n",
      "0.0029881801\n",
      "0.0036351036\n",
      "0.0001635474\n",
      "0.001063722\n",
      "0.006017875\n",
      "0.012763721\n",
      "0.01936726\n",
      "0.0002923064\n",
      "0.000919457\n",
      "0.0004814664\n",
      "0.0048850607\n",
      "0.01188092\n",
      "0.00077671075\n",
      "0.00026821886\n",
      "5.2076513e-05\n",
      "0.0017610989\n",
      "0.005991316\n",
      "0.011320448\n",
      "0.010685269\n",
      "0.009473941\n",
      "0.00851423\n",
      "0.0078033702\n",
      "0.00031582217\n",
      "0.00028620832\n",
      "0.0034124048\n",
      "0.0097992\n",
      "0.018455708\n",
      "0.0011437294\n",
      "0.0014390778\n",
      "0.00062783004\n",
      "0.0012717545\n",
      "0.003945718\n",
      "0.0002147993\n",
      "0.00011408253\n",
      "2.945324e-05\n",
      "0.0006312173\n",
      "0.0018173862\n",
      "0.0019829618\n",
      "0.0005787909\n",
      "0.00012888116\n",
      "0.00047294315\n",
      "0.0023350294\n",
      "0.0007638957\n",
      "0.005072442\n",
      "0.012169747\n",
      "0.018375108\n",
      "0.022781083\n",
      "0.00062019523\n",
      "0.002036931\n",
      "0.001655862\n",
      "0.006019837\n",
      "0.019989751\n",
      "0.00021734688\n",
      "3.3240794e-05\n",
      "4.432049e-05\n",
      "0.0015222419\n",
      "0.004642259\n",
      "0.00042635\n",
      "0.004140445\n",
      "0.0053119725\n",
      "0.004122525\n",
      "0.0012506996\n",
      "0.0001290222\n",
      "0.0009514254\n",
      "0.00016561469\n",
      "0.0044356594\n",
      "0.011499835\n",
      "0.0012805557\n",
      "0.0011592344\n",
      "0.004365502\n",
      "0.0076545677\n",
      "0.010531304\n",
      "1.6730466e-05\n",
      "0.0004454194\n",
      "0.005018517\n",
      "0.013595352\n",
      "0.024796775\n",
      "0.00011239908\n",
      "2.2869977e-05\n",
      "0.0009184946\n",
      "0.0036746631\n",
      "0.008078949\n",
      "0.0024015687\n",
      "0.0016096528\n",
      "0.0009007282\n",
      "0.00018099514\n",
      "0.0016638247\n",
      "0.0074383244\n",
      "0.005379346\n",
      "0.003952923\n",
      "0.0028260534\n",
      "0.001941982\n",
      "9.414328e-06\n",
      "0.000636226\n",
      "0.0011731462\n",
      "0.0013390857\n",
      "0.0011263409\n",
      "0.00038220675\n",
      "0.00036874294\n",
      "0.0019056109\n",
      "0.0083793\n",
      "0.018752225\n",
      "0.0016912268\n",
      "0.0035531642\n",
      "0.009199427\n",
      "0.01442941\n",
      "0.018797843\n",
      "0.006846148\n",
      "0.0050502205\n",
      "0.01518039\n",
      "0.023061233\n",
      "0.02919235\n",
      "0.0006300444\n",
      "0.0014589224\n",
      "0.0018305099\n",
      "0.0022043295\n",
      "0.010620003\n",
      "0.0012923535\n",
      "0.0003752286\n",
      "0.00053547637\n",
      "0.0044003897\n",
      "0.010517086\n",
      "0.0003248731\n",
      "0.0007242824\n",
      "0.00168317\n",
      "0.010660267\n",
      "0.025130806\n",
      "0.010242367\n",
      "0.0041198167\n",
      "0.0022343898\n",
      "0.008231712\n",
      "0.0134236505\n",
      "0.0058023883\n",
      "0.00048244835\n",
      "0.0038015803\n",
      "0.0051881336\n",
      "0.00542937\n",
      "3.6257614e-05\n",
      "2.4326311e-05\n",
      "0.00040811574\n",
      "0.0010728419\n",
      "0.001802423\n",
      "0.00010078619\n",
      "0.00015491873\n",
      "6.62708e-05\n",
      "0.00060725264\n",
      "0.0018437187\n",
      "0.00015750417\n",
      "3.289624e-05\n",
      "0.0015197782\n",
      "0.0053616585\n",
      "0.0113034295\n",
      "0.0011626245\n",
      "4.9829425e-05\n",
      "4.7567315e-05\n",
      "0.0011293355\n",
      "0.0033676843\n",
      "0.0007586277\n",
      "0.0044105924\n",
      "0.02217307\n",
      "0.04391045\n",
      "0.0634213\n",
      "0.0011386555\n",
      "0.00080845697\n",
      "0.00074795785\n",
      "0.00078818016\n",
      "0.0008821989\n"
     ]
    }
   ],
   "source": [
    "bboxes = valid_pred_bboxs(pred_bboxes=predicted_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6e9aba2c8ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
